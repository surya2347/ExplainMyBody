"""
ì¸ë°”ë”” ê²°ê³¼ì§€ ì´ˆì •ë°€ ë§¤ì¹­ - ì›ê·¼ ë³€í™˜ ì¶”ê°€
- 4ê°œ ê¼­ì§€ì  ê²€ì¶œ ë° ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ê¸°ìš¸ì–´ì§„ ë¬¸ì„œ ì •ë ¬
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from contextlib import contextmanager
import tempfile

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['FLAGS_use_mkldnn'] = '0' # MKLDNN ì‚¬ìš© ë¹„í™œì„±í™”
os.environ['FLAGS_enable_pir_api'] = '0' # PIR API ì‚¬ìš© ë¹„í™œì„±í™”
os.environ['FLAGS_enable_executor_v2'] = '0' # Executor V2 ì‚¬ìš© ë¹„í™œì„±í™”
os.environ['DISABLE_MODEL_SOURCE_CHECK'] = 'True' # ëª¨ë¸ ì†ŒìŠ¤ ì²´í¬ ë¹„í™œì„±í™”

import cv2
import json
import re
import numpy as np
import difflib
from paddleocr import PaddleOCR


@dataclass
class MatchConfig:
    """ë§¤ì¹­ ì„¤ì • ë°ì´í„° í´ë˜ìŠ¤"""
    regex: str
    y_range: Tuple[int, int]
    direction: str
    x_tolerance: int = 800
    y_tolerance: int = 50
    allow_zero: bool = False


class ConfigManager:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_default_targets() -> Dict[str, MatchConfig]:
        """ê¸°ë³¸ íƒ€ê²Ÿ ì„¤ì • ë°˜í™˜"""
        return {
            "ì‹ ì¥": MatchConfig(r"(\d{3})", (130, 220), "down"),
            "ì—°ë ¹": MatchConfig(r"(\d{2})", (130, 220), "down"),
            "ì„±ë³„": MatchConfig(r"(ë‚¨ì„±|ì—¬ì„±|ë‚¨|ì—¬)$", (130, 220), "down"),
            "ì²´ìˆ˜ë¶„": MatchConfig(r"(\d+\.\d+)", (300, 380), "right"),
            "ë‹¨ë°±ì§ˆ": MatchConfig(r"(\d+\.\d+)", (370, 440), "right"),
            "ë¬´ê¸°ì§ˆ": MatchConfig(r"(\d+\.\d+)", (430, 490), "right"),
            "ì²´ì§€ë°©": MatchConfig(r"(\d+\.\d+)", (480, 550), "right"),
            "ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (740, 830), "right"),
            "ê³¨ê²©ê·¼ëŸ‰": MatchConfig(r"(\d+\.\d+)", (830, 910), "right"),
            "ì²´ì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.\d+)", (910, 980), "right"),
            "ì ì •ì²´ì¤‘": MatchConfig(r"(\d+\.\d+)", (550, 630), "right"),
            "ì²´ì¤‘ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (580, 670), "right", allow_zero=True),
            "ì§€ë°©ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+)", (630, 710), "right", allow_zero=True),
            "ê·¼ìœ¡ì¡°ì ˆ": MatchConfig(r"([-+]?\d+\.\d+|0\.0)", (670, 750), "right", allow_zero=True),
            "ë³µë¶€ì§€ë°©ë¥ ": MatchConfig(r"(\d\.\d{2})", (850, 1050), "down"),
            "ë‚´ì¥ì§€ë°©ë ˆë²¨": MatchConfig(r"(\d+)", (950, 1150), "down"),
            "BMI": MatchConfig(r"(\d+\.\d+)", (1120, 1180), "right"),
            "ì²´ì§€ë°©ë¥ ": MatchConfig(r"(\d+\.\d+)", (1200, 1260), "right"),
            "ì œì§€ë°©ëŸ‰": MatchConfig(r"(\d+\.?\d*)", (1140, 1210), "right"),
            "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": MatchConfig(r"(\d{4})", (1210, 1260), "right"),
            "ë¹„ë§Œë„": MatchConfig(r"(\d+)", (1250, 1300), "right"),
            "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": MatchConfig(r"(\d{4})", (1290, 1350), "right"),
        }
    
    @staticmethod
    def get_correction_map() -> Dict[str, str]:
        """ì˜¤íƒ€ êµì • ë§µ ë°˜í™˜"""
        return {
            "ì²™ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘", "ì •ì²´ì¤‘": "ì ì •ì²´ì¤‘",
            "ì²´ì§€ë°©ë¥¨": "ì²´ì§€ë°©ë¥ ", "ì²´ì§€ë°©ìœ¨": "ì²´ì§€ë°©ë¥ ",
            "ê³¨ê²©ê·¹ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ê·¹ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰",
            "ë¬´ê¸°ì‹¤": "ë¬´ê¸°ì§ˆ", "ë³´ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ",
            "ë¶€ì§€ë°©ë¥ ": "ë³µë¶€ì§€ë°©ë¥ ", "ë‚´ì¥ì§€ë°©ë ˆë¹Œ": "ë‚´ì¥ì§€ë°©ë ˆë²¨",
            "ì œì§€ë°©ë¥¨": "ì œì§€ë°©ëŸ‰", "ì œì§€ë°©ë¥ ": "ì œì§€ë°©ëŸ‰",
            "ìœ¨ê·¼ë¡ ": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "ìœ¨ê·¼ë¥œ": "ê³¨ê²©ê·¼ëŸ‰",
            "ê·¼ìœ¡ëŸ‰": "ê³¨ê²©ê·¼ëŸ‰", "Skeletal": "ê³¨ê²©ê·¼ëŸ‰",
            "MuscleMass": "ê³¨ê²©ê·¼ëŸ‰", "SkeletalMtiscleMass": "ê³¨ê²©ê·¼ëŸ‰",
            "ë‹¨ë°±ì¹ ": "ë‹¨ë°±ì§ˆ", "ë¬´ê¸°ì¹ ": "ë¬´ê¸°ì§ˆ", 
            "ë‹¨ë°±ì ˆ": "ë‹¨ë°±ì§ˆ", "ê³¨ê²©ê·¼": "ê³¨ê²©ê·¼ëŸ‰"
        }


@contextmanager
def temporary_file(suffix='.jpg'):
    """ì„ì‹œ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    temp_path = temp_file.name
    temp_file.close()
    
    try:
        yield temp_path
    finally:
        try:
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        except:
            pass


class DocumentRectifier:
    """ë¬¸ì„œ 4ì  ì›ê·¼ ë³€í™˜ í´ë˜ìŠ¤"""
    
    @staticmethod
    def order_points(pts: np.ndarray) -> np.ndarray:
        """4ê°œì˜ ì ì„ [ì¢Œìƒ, ìš°ìƒ, ìš°í•˜, ì¢Œí•˜] ìˆœì„œë¡œ ì •ë ¬"""
        rect = np.zeros((4, 2), dtype="float32")
        s = pts.sum(axis=1)
        rect[0] = pts[np.argmin(s)]
        rect[2] = pts[np.argmax(s)]
        diff = np.diff(pts, axis=1)
        rect[1] = pts[np.argmin(diff)]
        rect[3] = pts[np.argmax(diff)]
        return rect
    
    @staticmethod
    def calculate_skew_score(corners: np.ndarray, img_shape: tuple) -> float:
        """
        ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚° (0~100, ë†’ì„ìˆ˜ë¡ ê¸°ìš¸ì–´ì§)
        
        Returns:
            0-20: ê±°ì˜ ì •ë©´ (ì›ê·¼ ë³€í™˜ ë¶ˆí•„ìš”)
            20-50: ì•½ê°„ ê¸°ìš¸ì–´ì§ (ì„ íƒì )
            50+: ì‹¬í•˜ê²Œ ê¸°ìš¸ì–´ì§ (ì›ê·¼ ë³€í™˜ í•„ìš”)
        """
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        h, w = img_shape[:2]
        
        # 1. ë©´ì  ë¹„ìœ¨ (ì›ê·¼ ì™œê³¡ì´ í¬ë©´ ë©´ì ì´ ì¤„ì–´ë“¦)
        detected_area = cv2.contourArea(corners)
        image_area = h * w
        area_ratio = detected_area / image_area
        area_score = (1 - area_ratio) * 100  # ë©´ì ì´ ì‘ì„ìˆ˜ë¡ ì ìˆ˜ ë†’ìŒ
        
        # 2. ê°ë„ ì™œê³¡ (ì§ì‚¬ê°í˜•ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€)
        def angle_between(p1, p2, p3):
            """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
            v1 = p1 - p2
            v2 = p3 - p2
            angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))
            return np.degrees(angle)
        
        angles = [
            angle_between(tl, tr, br),  # ìš°ìƒ ê°ë„
            angle_between(tr, br, bl),  # ìš°í•˜ ê°ë„
            angle_between(br, bl, tl),  # ì¢Œí•˜ ê°ë„
            angle_between(bl, tl, tr)   # ì¢Œìƒ ê°ë„
        ]
        
        # 90ë„ì—ì„œ ë²—ì–´ë‚œ ì •ë„
        angle_deviation = np.mean([abs(angle - 90) for angle in angles])
        angle_score = angle_deviation * 2  # 0~180 ë²”ìœ„ë¥¼ 0~100ìœ¼ë¡œ
        
        # 3. ë³€ ê¸¸ì´ ë¹„ìœ¨ (í‰í–‰í•œ ë³€ë“¤ì˜ ê¸¸ì´ê°€ ë¹„ìŠ·í•´ì•¼ í•¨)
        top_width = np.linalg.norm(tr - tl)
        bottom_width = np.linalg.norm(br - bl)
        left_height = np.linalg.norm(bl - tl)
        right_height = np.linalg.norm(br - tr)
        
        width_ratio = abs(top_width - bottom_width) / max(top_width, bottom_width)
        height_ratio = abs(left_height - right_height) / max(left_height, right_height)
        ratio_score = (width_ratio + height_ratio) * 50
        
        # ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
        total_score = (area_score * 0.3 + angle_score * 0.5 + ratio_score * 0.2)
        
        return min(100, total_score)
    
    @staticmethod
    def find_document_corners(img: np.ndarray) -> Optional[np.ndarray]:
        """ìœ¤ê³½ì„  ê²€ì¶œë¡œ ë¬¸ì„œ 4ê°œ ê¼­ì§€ì  ì°¾ê¸°"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
            
            for contour in contours:
                peri = cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, 0.02 * peri, True)
                if len(approx) == 4:
                    return approx.reshape(4, 2)
            return None
        except:
            return None
    
    @staticmethod
    def apply_perspective_transform(img: np.ndarray, corners: np.ndarray) -> np.ndarray:
        """ì›ê·¼ ë³€í™˜ìœ¼ë¡œ ë¬¸ì„œë¥¼ ì •ë©´ìœ¼ë¡œ í¼ì¹˜ê¸°"""
        rect = DocumentRectifier.order_points(corners)
        (tl, tr, br, bl) = rect
        
        widthA = np.sqrt((br[0] - bl[0]) ** 2 + (br[1] - bl[1]) ** 2)
        widthB = np.sqrt((tr[0] - tl[0]) ** 2 + (tr[1] - tl[1]) ** 2)
        maxWidth = max(int(widthA), int(widthB))
        
        heightA = np.sqrt((tr[0] - br[0]) ** 2 + (tr[1] - br[1]) ** 2)
        heightB = np.sqrt((tl[0] - bl[0]) ** 2 + (tl[1] - bl[1]) ** 2)
        maxHeight = max(int(heightA), int(heightB))
        
        dst = np.array([
            [0, 0],
            [maxWidth - 1, 0],
            [maxWidth - 1, maxHeight - 1],
            [0, maxHeight - 1]
        ], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect, dst)
        warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))
        return warped
    
    @staticmethod
    def rectify_auto(img: np.ndarray, threshold: float = 15.0) -> Tuple[np.ndarray, bool, float]:
        """
        ìë™ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ íŒë‹¨í•˜ì—¬ ì›ê·¼ ë³€í™˜ ì ìš©
        
        Args:
            img: ì…ë ¥ ì´ë¯¸ì§€
            threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (ì´ ê°’ ì´ìƒì´ë©´ ë³€í™˜ ì ìš©)
        
        Returns:
            (ë³€í™˜ëœ ì´ë¯¸ì§€, ë³€í™˜ ì ìš© ì—¬ë¶€, ê¸°ìš¸ê¸° ì ìˆ˜)
        """
        try:
            corners = DocumentRectifier.find_document_corners(img)
            
            if corners is None:
                return img, False, 0.0
            
            # [NEW] ë©´ì  ë¹„ìœ¨ ì²´í¬ (ì „ì²´ì˜ 30% ë¯¸ë§Œì´ë©´ ë¬´ì‹œ)
            h, w = img.shape[:2]
            detected_area = cv2.contourArea(corners)
            image_area = h * w
            area_ratio = detected_area / image_area
            
            if area_ratio < 0.3:
                return img, False, 0.0
            
            # ê¸°ìš¸ê¸° ì ìˆ˜ ê³„ì‚°
            skew_score = DocumentRectifier.calculate_skew_score(corners, img.shape)
            
            # ì„ê³„ê°’ ì´ìƒì´ë©´ ì›ê·¼ ë³€í™˜ ì ìš©
            if skew_score >= threshold:
                warped = DocumentRectifier.apply_perspective_transform(img, corners)
                return warped, True, skew_score
            else:
                return img, False, skew_score
                
        except:
            return img, False, 0.0


class InBodyMatcher:
    """ì¸ë°”ë”” ê²°ê³¼ì§€ ë§¤ì¹­ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: Optional[str] = None, 
                 auto_perspective: bool = True,
                 skew_threshold: float = 15.0):
        """
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)
            auto_perspective: ìë™ ì›ê·¼ ë³€í™˜ í™œì„±í™” (ê¸°ë³¸: True)
            skew_threshold: ê¸°ìš¸ê¸° ì„ê³„ê°’ (0-100, ê¸°ë³¸: 15.0)
        """
        try:
            # PaddleOCR ë¡œê¹… ì–µì œ
            import logging
            logging.getLogger('ppocr').setLevel(logging.ERROR)
            
            self.ocr = PaddleOCR(
                lang='korean',
                ocr_version='PP-OCRv5',
                text_det_limit_side_len=2560,
                text_det_unclip_ratio=2.0,
                use_textline_orientation=True
            )
        except Exception as e:
            raise Exception(f"PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        self.correction_map = ConfigManager.get_correction_map()
        self.targets = ConfigManager.get_default_targets()
        self.auto_perspective = auto_perspective
        self.skew_threshold = skew_threshold
        
        if config_path and os.path.exists(config_path):
            self._load_config(config_path)
    
    def _load_config(self, config_path: str):
        """ì™¸ë¶€ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            pass
    
    def _deskew(self, img: np.ndarray) -> np.ndarray:
        """Hough Transformì„ ì´ìš©í•œ ë¯¸ì„¸ ê¸°ìš¸ê¸° ë³´ì •"""
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)
            
            if lines is not None:
                angles = []
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    angle = np.degrees(np.arctan2(y2 - y1, x2 - x1))
                    if -10 < angle < 10:
                        angles.append(angle)
                
                if angles:
                    median_angle = np.median(angles)
                    (h, w) = img.shape[:2]
                    center = (w // 2, h // 2)
                    M = cv2.getRotationMatrix2D(center, median_angle, 1.0)
                    img = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
            
            return img
        except:
            return img
    
    def _preprocess_image(self, img: np.ndarray) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            img = self._deskew(img)
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            enhanced = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2BGR)
            return enhanced
        except:
            return img
    
    def _extract_nodes(self, image_path: str) -> List[Dict[str, Any]]:
        """OCRì„ í†µí•´ í…ìŠ¤íŠ¸ ë…¸ë“œ ì¶”ì¶œ"""
        try:
            result = self.ocr.predict(input=image_path)
            all_nodes = []
            
            if result:
                for res in result:
                    dt_polys = res.get('dt_polys', [])
                    rec_texts = res.get('rec_texts', [])
                    rec_scores = res.get('rec_scores', [])
                    
                    for poly, text, conf in zip(dt_polys, rec_texts, rec_scores):
                        pts = np.array(poly)
                        x_min, y_min = pts.min(axis=0)
                        x_max, y_max = pts.max(axis=0)
                        
                        node = {
                            'text': text.strip().replace(" ", "").replace("|", ""),
                            'bbox': [int(x_min), int(y_min), int(x_max), int(y_max)],
                            'h': int(y_max - y_min),
                            'center': [(x_min + x_max) / 2, (y_min + y_max) / 2],
                            'conf': float(conf)
                        }
                        all_nodes.append(node)
            
            return all_nodes
        except:
            return []
    
    def _correct_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì˜¤íƒ€ êµì •"""
        return self.correction_map.get(text, text)
    
    def _find_key_node(self, key: str, nodes: List[Dict], y_range: Tuple[int, int]) -> Optional[Dict]:
        """í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ë…¸ë“œ ì°¾ê¸°"""
        yr_min, yr_max = y_range
        
        candidates = []
        for node in nodes:
            # Y ë²”ìœ„ í™•ì¥ (Â±50ìœ¼ë¡œ ì¶•ì†Œ)
            if not (yr_min - 50 <= node['center'][1] <= yr_max + 50):
                continue
            
            # ê´„í˜¸ ì œê±°
            text_without_parens = re.sub(r'\([^)]*\)', '', node['text'])
            corrected_text = self._correct_text(text_without_parens)
            original_corrected = self._correct_text(node['text'])
            
            # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í¬í•¨í•˜ëŠ” ê²½ìš°
            if key in corrected_text or key in original_corrected:
                candidates.append(node)
            # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
            else:
                ratio1 = difflib.SequenceMatcher(None, key, corrected_text).ratio()
                ratio2 = difflib.SequenceMatcher(None, key, original_corrected).ratio()
                max_ratio = max(ratio1, ratio2)
                
                if max_ratio > 0.5:
                    candidates.append(node)
        
        if candidates:
            # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ë…¸ë“œ ì„ íƒ
            best = max(candidates, key=lambda x: x['conf'])
            return best
        
        return None
    
    def _match_value(self, key: str, key_node: Dict, config: MatchConfig, 
                     nodes: List[Dict]) -> Optional[str]:
        """ê°’ ë…¸ë“œ ë§¤ì¹­"""
        yr_min, yr_max = config.y_range
        candidates = []
        
        # ë””ë²„ê·¸: BMIì™€ ì²´ì§€ë°©ë¥ ë§Œ
        debug = key in ["BMI", "ì²´ì§€ë°©ë¥ "]
        
        for node in nodes:
            if node == key_node:
                continue
            
            # í…ìŠ¤íŠ¸ ì •ê·œí™”
            clean_text = re.sub(r'\(.*?\)', '', node['text'])
            clean_text = clean_text.replace('I', '1').replace('l', '1').replace(',', '.')
            
            # ì •ê·œì‹ ë§¤ì¹­
            match = re.search(config.regex, clean_text)
            if not match:
                continue
            
            # ê°’ ì¶”ì¶œ
            if "ì¡°ì ˆ" in key:
                val = match.group(0)
            else:
                val = match.group(1)
            
            # ìœ„ì¹˜ ê³„ì‚°
            dx = node['center'][0] - key_node['bbox'][2] if config.direction == "right" else abs(node['center'][0] - key_node['center'][0])
            dy = abs(node['center'][1] - key_node['center'][1])
            
            # ROI ì²´í¬ - í‚¤ì›Œë“œ ê¸°ì¤€ì´ ì•„ë‹Œ ê°’ ìì²´ì˜ Y ìœ„ì¹˜ë¡œ íŒë‹¨
            # ì²´ì§€ë°©ë¥ ì€ 1210 ì´í•˜ì˜ ê°’ì€ ì œì™¸ (BMI ì˜ì—­)
            if key == "ì²´ì§€ë°©ë¥ " and node['center'][1] < 1210:
                continue
            
            in_roi = (yr_min - 50 <= node['center'][1] <= yr_max + 50)
            is_right_dir = (config.direction == "right" and -50 < dx < config.x_tolerance and dy < 80)
            is_down_dir = (config.direction == "down" and 0 < (node['center'][1] - key_node['bbox'][3]) < 300 and abs(node['center'][0] - key_node['center'][0]) < 150)
            
            if not in_roi:
                continue
            
            if not (is_right_dir or is_down_dir):
                continue
            
            # ë””ë²„ê·¸ ì¶œë ¥
            if debug and val in ["26.9", "26.5"]:
                print(f"[{key}] í›„ë³´: {val} at y={node['center'][1]:.0f}, h={node['h']}, dy={dy:.0f}, in_roi={in_roi}, range=({yr_min-50}~{yr_max+50})")
            
            # 0ê°’ í•„í„°ë§ (í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ìš°)
            if not config.allow_zero and val in ["0.0", "0", "+0.0", "-0.0"]:
                continue
            
            # ëˆˆê¸ˆì„  ê°’ í•„í„°ë§ (ì‘ì€ ê¸€ì”¨)
            is_scale_mark = node.get('h', 0) < 30
            
            # ê±°ë¦¬ ì ìˆ˜ ê³„ì‚° (ìˆ˜ì§ ì •ë ¬ ìš°ì„ )
            dist_score = (dy * 300) + abs(dx)
            
            # í° ê¸€ì”¨ì— ë³´ë„ˆìŠ¤ ì ìˆ˜ (ì‹¤ì œ ê°’)
            if node.get('h', 0) > 35:
                dist_score -= 20000
            
            # ëˆˆê¸ˆì„ ì— í˜ë„í‹°
            if is_scale_mark:
                dist_score += 50000
            
            if debug and val in ["26.9", "26.5"]:
                print(f"  -> dist_score={dist_score:.0f}, is_scale_mark={is_scale_mark}")
            
            candidates.append((dist_score, val, node, dx, dy))
        
        if candidates:
            candidates.sort(key=lambda x: x[0])
            best_match = candidates[0]
            
            if debug:
                print(f"[{key}] ìµœì¢… ì„ íƒ: {best_match[1]} (score={best_match[0]:.0f})")
                print(f"  í‚¤ì›Œë“œ ìœ„ì¹˜: y={key_node['center'][1]:.0f}")
                print(f"  ì „ì²´ í›„ë³´: {[(c[1], f'{c[0]:.0f}') for c in candidates[:3]]}")
            
            return best_match[1]
        
        if debug:
            print(f"[{key}] í›„ë³´ ì—†ìŒ!")
        
        return None
    
    def _extract_segment_evaluations(self, nodes: List[Dict]) -> Dict[str, str]:
        """ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ"""
        evals = ["í‘œì¤€ì´í•˜", "í‘œì¤€ì´ìƒ", "í‘œì¤€"]
        seg_nodes = sorted(
            [n for n in nodes if any(ev in n['text'] for ev in evals) and (1400 <= n['center'][1] <= 1900)],
            key=lambda x: x['center'][1]
        )
        
        row_top = sorted([n for n in seg_nodes if n['center'][1] < 1580], key=lambda x: x['center'][0])
        row_mid = sorted([n for n in seg_nodes if 1580 <= n['center'][1] <= 1700], key=lambda x: x['center'][0])
        row_bot = sorted([n for n in seg_nodes if n['center'][1] > 1700], key=lambda x: x['center'][0])
        
        results = {}
        
        try:
            if len(row_top) >= 4:
                results["ì™¼ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_top[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_top[3]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_mid) >= 2:
                results["ë³µë¶€ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_mid[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ë³µë¶€ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_mid[1]['text']), "ë¯¸ê²€ì¶œ")
            
            if len(row_bot) >= 4:
                results["ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[0]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"] = next((ev for ev in evals if ev in row_bot[1]['text']), "ë¯¸ê²€ì¶œ")
                results["ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[2]['text']), "ë¯¸ê²€ì¶œ")
                results["ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"] = next((ev for ev in evals if ev in row_bot[3]['text']), "ë¯¸ê²€ì¶œ")
        except:
            pass
        
        return results
    
    def extract_and_match(self, image_path: str) -> Dict[str, Optional[str]]:
        """ì´ë¯¸ì§€ì—ì„œ ì¸ë°”ë”” ë°ì´í„° ì¶”ì¶œ ë° ë§¤ì¹­"""
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        try:
            src_img = cv2.imread(image_path)
            if src_img is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {src_img.shape[:2]}")
            
            # [NEW] ìë™ ì›ê·¼ ë³€í™˜ (ê¸°ìš¸ê¸° ìë™ íŒë‹¨)
            if self.auto_perspective:
                src_img, applied, skew_score = DocumentRectifier.rectify_auto(
                    src_img, threshold=self.skew_threshold
                )
                if applied:
                    print(f"ğŸ”„ ì›ê·¼ ë³€í™˜ ì ìš© (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f})")
                else:
                    if skew_score > 0:
                        print(f"âœ“ ì •ë©´ ë¬¸ì„œ (ê¸°ìš¸ê¸° ì ìˆ˜: {skew_score:.1f}, ì„ê³„ê°’: {self.skew_threshold})")
            
            # í•´ìƒë„ ì •ê·œí™”
            target_h = 2400
            ratio = target_h / src_img.shape[0]
            img = cv2.resize(
                src_img,
                (int(src_img.shape[1] * ratio), target_h),
                interpolation=cv2.INTER_LANCZOS4
            )
            
            print(f"ğŸ“ ì •ê·œí™”ëœ í¬ê¸°: {img.shape[:2]}")
            
            # ì „ì²˜ë¦¬ ë° OCR
            with temporary_file() as temp_path:
                processed_img = self._preprocess_image(img)
                cv2.imwrite(temp_path, processed_img)
                all_nodes = self._extract_nodes(temp_path)
            
            print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë…¸ë“œ: {len(all_nodes)}ê°œ")
            
            if not all_nodes:
                print("âš ï¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # ë§¤ì¹­ ìˆ˜í–‰
            matched_data = {}
            
            for key, config in self.targets.items():
                key_node = self._find_key_node(key, all_nodes, config.y_range)
                
                if not key_node:
                    matched_data[key] = None
                    continue
                
                value = self._match_value(key, key_node, config, all_nodes)
                matched_data[key] = value
            
            # ë¶€ìœ„ë³„ í‰ê°€ ì¶”ì¶œ
            segment_results = self._extract_segment_evaluations(all_nodes)
            matched_data.update(segment_results)
            
            # ë§¤ì¹­ í†µê³„
            detected = sum(1 for v in matched_data.values() if v is not None)
            total = len(matched_data)
            print(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {detected}/{total} í•­ëª© ({detected/total*100:.1f}%)")
            
            return matched_data
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def save_results(self, results: Dict, output_path: str, format: str = 'json'):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            if format == 'json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            elif format in ['dict', 'python']:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write("# InBody ì¸¡ì • ê²°ê³¼\n")
                    f.write("inbody_data = ")
                    f.write(json.dumps(results, ensure_ascii=False, indent=4))
                print(f"ğŸ’¾ Python í˜•ì‹ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({output_path}): {e}")
    
    def get_structured_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
        
        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ë¡œ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬
        """
        structured = {
            "ê¸°ë³¸ì •ë³´": {
                "ì‹ ì¥": results.get("ì‹ ì¥"),
                "ì—°ë ¹": results.get("ì—°ë ¹"),
                "ì„±ë³„": results.get("ì„±ë³„"),
            },
            "ì²´ì„±ë¶„": {
                "ì²´ìˆ˜ë¶„": results.get("ì²´ìˆ˜ë¶„"),
                "ë‹¨ë°±ì§ˆ": results.get("ë‹¨ë°±ì§ˆ"),
                "ë¬´ê¸°ì§ˆ": results.get("ë¬´ê¸°ì§ˆ"),
                "ì²´ì§€ë°©": results.get("ì²´ì§€ë°©"),
            },
            "ì²´ì¤‘ê´€ë¦¬": {
                "ì²´ì¤‘": results.get("ì²´ì¤‘"),
                "ê³¨ê²©ê·¼ëŸ‰": results.get("ê³¨ê²©ê·¼ëŸ‰"),
                "ì²´ì§€ë°©ëŸ‰": results.get("ì²´ì§€ë°©ëŸ‰"),
                "ì ì •ì²´ì¤‘": results.get("ì ì •ì²´ì¤‘"),
                "ì²´ì¤‘ì¡°ì ˆ": results.get("ì²´ì¤‘ì¡°ì ˆ"),
                "ì§€ë°©ì¡°ì ˆ": results.get("ì§€ë°©ì¡°ì ˆ"),
                "ê·¼ìœ¡ì¡°ì ˆ": results.get("ê·¼ìœ¡ì¡°ì ˆ"),
            },
            "ë¹„ë§Œë¶„ì„": {
                "BMI": results.get("BMI"),
                "ì²´ì§€ë°©ë¥ ": results.get("ì²´ì§€ë°©ë¥ "),
                "ë³µë¶€ì§€ë°©ë¥ ": results.get("ë³µë¶€ì§€ë°©ë¥ "),
                "ë‚´ì¥ì§€ë°©ë ˆë²¨": results.get("ë‚´ì¥ì§€ë°©ë ˆë²¨"),
                "ë¹„ë§Œë„": results.get("ë¹„ë§Œë„"),
            },
            "ê¸°íƒ€": {
                "ì œì§€ë°©ëŸ‰": results.get("ì œì§€ë°©ëŸ‰"),
                "ê¸°ì´ˆëŒ€ì‚¬ëŸ‰": results.get("ê¸°ì´ˆëŒ€ì‚¬ëŸ‰"),
                "ê¶Œì¥ì„­ì·¨ì—´ëŸ‰": results.get("ê¶Œì¥ì„­ì·¨ì—´ëŸ‰"),
            },
            "ë¶€ìœ„ë³„ê·¼ìœ¡ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ê·¼ìœ¡"),
                "ë³µë¶€": results.get("ë³µë¶€ ê·¼ìœ¡"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ê·¼ìœ¡"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ê·¼ìœ¡"),
            },
            "ë¶€ìœ„ë³„ì²´ì§€ë°©ë¶„ì„": {
                "ì™¼ìª½íŒ”": results.get("ì™¼ìª½íŒ” ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½íŒ”": results.get("ì˜¤ë¥¸ìª½íŒ” ì²´ì§€ë°©"),
                "ë³µë¶€": results.get("ë³µë¶€ ì²´ì§€ë°©"),
                "ì™¼ìª½í•˜ì²´": results.get("ì™¼ìª½í•˜ì²´ ì²´ì§€ë°©"),
                "ì˜¤ë¥¸ìª½í•˜ì²´": results.get("ì˜¤ë¥¸ìª½í•˜ì²´ ì²´ì§€ë°©"),
            }
        }
        
        return structured


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ëª…ë ¹í–‰ ì¸ìê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 444.jpg ì‚¬ìš©
    img_path = sys.argv[1] if len(sys.argv) > 1 else "444.jpg"
    
    try:
        print("=" * 60)
        print("InBody OCR ì²˜ë¦¬ ì‹œì‘")
        print("=" * 60)
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(img_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
            sys.exit(1)
        
        print(f"âœ“ íŒŒì¼ í™•ì¸: {img_path}")
        
        # ìë™ ì›ê·¼ ë³€í™˜ (ê¸°ë³¸ í™œì„±í™”)
        matcher = InBodyMatcher(
            auto_perspective=True,
            skew_threshold=15.0
        )
        
        print("âœ“ InBodyMatcher ì´ˆê¸°í™” ì™„ë£Œ")
        print()
        
        result = matcher.extract_and_match(img_path)
        
        # ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not result:
            print("\nâŒ OCR ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            print("\nê°€ëŠ¥í•œ ì›ì¸:")
            print("  1. ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŒ")
            print("  2. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            print("  3. ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ ì˜¤ë¥˜")
            print("\ní•´ê²° ë°©ë²•:")
            print("  - ì´ë¯¸ì§€ íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸")
            print("  - ì´ë¯¸ì§€ê°€ ì¶©ë¶„íˆ ì„ ëª…í•œì§€ í™•ì¸")
            print("  - ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸")
            sys.exit(1)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 50)
        print(f"{'í•­ëª©':<15} | {'ê²°ê³¼'}")
        print("-" * 50)
        
        # ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_data = False
        for key, val in result.items():
            if val and val != "ë¯¸ê²€ì¶œ":
                has_data = True
            print(f"{key:<15} | {val if val else 'ë¯¸ê²€ì¶œ'}")
        
        print("=" * 50)
        
        if not has_data:
            print("\nâš ï¸ ëª¨ë“  í•­ëª©ì´ ë¯¸ê²€ì¶œì…ë‹ˆë‹¤!")
            print("\në¬¸ì œ ì§„ë‹¨ì„ ìœ„í•´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”:")
            print("  - auto_perspectiveë¥¼ Falseë¡œ ì‹œë„")
            print("  - ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸")
        else:
            # ì €ì¥
            matcher.save_results(result, "inbody_result.json", format='json')
            
            structured = matcher.get_structured_results(result)
            matcher.save_results(structured, "inbody_result_structured.json", format='json')
            
            # ë”•ì…”ë„ˆë¦¬ ì›ë³¸ ì¶œë ¥ (ìš”ì²­ ì‚¬í•­)
            print("\n" + "=" * 50)
            print("ğŸ“¦ ì¶”ì¶œëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬")
            print("=" * 50)
            print(json.dumps(structured, ensure_ascii=False, indent=2))
            print("=" * 50)
            
            print("\nâœ… ì™„ë£Œ")
        
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        print("\nìƒì„¸ ì˜¤ë¥˜:")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()